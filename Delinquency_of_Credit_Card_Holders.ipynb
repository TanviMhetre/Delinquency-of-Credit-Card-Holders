{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkks+uqDQ5MZcCVw0696VZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanviMhetre/Delinquency-of-Credit-Card-Holders/blob/main/Delinquency_of_Credit_Card_Holders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMEQsDlDt4LE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        ")\n",
        "\n",
        "# 1. Load dataset\n",
        "# If the CSV file is in the same folder, provide the filename below.\n",
        "df = pd.read_csv(\"/content/Delinquency_prediction_dataset.csv\")\n",
        "\n",
        "# Quick peek\n",
        "print(\"Rows, cols:\", df.shape)\n",
        "print(df.head(3))\n",
        "\n",
        "# 2. Select features\n",
        "features = [\n",
        "    \"Credit_Utilization\",\n",
        "    \"Missed_Payments\",\n",
        "    \"Income\",\n",
        "    \"Debt_to_Income_Ratio\",\n",
        "    \"Account_Tenure\",\n",
        "]\n",
        "X = df[features].copy()\n",
        "\n",
        "# 3. Define target variable\n",
        "y = df[\"Delinquent_Account\"].copy()\n",
        "\n",
        "# Basic target cleaning: ensure binary numeric (0/1)\n",
        "# Some datasets may already be numeric; enforce it properly.\n",
        "# If target contains non-numeric values like 'Yes'/'No' convert accordingly.\n",
        "if y.dtype == object:\n",
        "    # try converting to numeric\n",
        "    y_numeric = pd.to_numeric(y, errors=\"coerce\")\n",
        "    if y_numeric.isna().all():\n",
        "        # fallback: map common text to 0/1\n",
        "        mapping = {}\n",
        "        unique_vals = y.dropna().unique().tolist()\n",
        "        print(\"Target unique values:\", unique_vals)\n",
        "        # If values look like 'Yes'/'No' or 'Y'/'N' or '1'/'0', adapt mapping:\n",
        "        # We'll map any distinct non-null value to integer labels using factorize\n",
        "        y = pd.Series(pd.factorize(y.fillna(\"MISSING\"))[0])\n",
        "    else:\n",
        "        y = y_numeric.fillna(0).astype(int)\n",
        "else:\n",
        "    # If already numeric, ensure integers and handle NaNs\n",
        "    y = pd.to_numeric(y, errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "# Check distribution of target\n",
        "print(\"Target value counts:\\n\", y.value_counts())\n",
        "\n",
        "# 4. Preprocessing: handle missing values and scaling\n",
        "# Missing values appear in Income and Loan_Balance and others in dataset.\n",
        "# Here we impute numeric features with median.\n",
        "num_imputer = SimpleImputer(strategy=\"median\")\n",
        "X_imputed = pd.DataFrame(num_imputer.fit_transform(X), columns=features)\n",
        "\n",
        "# Some rows may still contain extreme or invalid values; it's okay for logistic regression.\n",
        "# Scale features (recommended for regularized logistic regression)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed), columns=features)\n",
        "\n",
        "# 5. Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "model = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# 7. Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\nEvaluation on test set:\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall: {rec:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "if y_proba is not None:\n",
        "    try:\n",
        "        roc_auc = roc_auc_score(y_test, y_proba)\n",
        "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(\"Could not compute ROC AUC:\", e)\n",
        "\n",
        "# Optional: show feature coefficients (importance)\n",
        "coef_df = pd.DataFrame(\n",
        "    {\"feature\": features, \"coefficient\": model.coef_.ravel()}\n",
        ").sort_values(by=\"coefficient\", key=abs, ascending=False)\n",
        "print(\"\\nFeature coefficients:\")\n",
        "print(coef_df)\n",
        "\n",
        "# Print test set size and positive class prevalence for context\n",
        "print(\"\\nTest set size:\", len(y_test))\n",
        "print(\"Positive class rate in test set:\", y_test.mean())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        ")\n",
        "\n",
        "# 1. Load dataset\n",
        "# If the CSV file is in the same folder, provide the filename below.\n",
        "df = pd.read_csv(\"/content/Delinquency_prediction_dataset.csv\")\n",
        "\n",
        "# Quick peek\n",
        "print(\"Rows, cols:\", df.shape)\n",
        "print(df.head(3))\n",
        "\n",
        "# 2. Select features\n",
        "features = [\n",
        "    \"Credit_Utilization\",\n",
        "    \"Missed_Payments\",\n",
        "    \"Income\",\n",
        "    \"Debt_to_Income_Ratio\",\n",
        "    \"Account_Tenure\",\n",
        "]\n",
        "X = df[features].copy()\n",
        "\n",
        "# 3. Define target variable\n",
        "y = df[\"Delinquent_Account\"].copy()\n",
        "\n",
        "# Basic target cleaning: ensure binary numeric (0/1)\n",
        "# Some datasets may already be numeric; enforce it properly.\n",
        "# If target contains non-numeric values like 'Yes'/'No' convert accordingly.\n",
        "if y.dtype == object:\n",
        "    # try converting to numeric\n",
        "    y_numeric = pd.to_numeric(y, errors=\"coerce\")\n",
        "    if y_numeric.isna().all():\n",
        "        # fallback: map common text to 0/1\n",
        "        mapping = {}\n",
        "        unique_vals = y.dropna().unique().tolist()\n",
        "        print(\"Target unique values:\", unique_vals)\n",
        "        # If values look like 'Yes'/'No' or 'Y'/'N' or '1'/'0', adapt mapping:\n",
        "        # We'll map any distinct non-null value to integer labels using factorize\n",
        "        y = pd.Series(pd.factorize(y.fillna(\"MISSING\"))[0])\n",
        "    else:\n",
        "        y = y_numeric.fillna(0).astype(int)\n",
        "else:\n",
        "    # If already numeric, ensure integers and handle NaNs\n",
        "    y = pd.to_numeric(y, errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "# Check distribution of target\n",
        "print(\"Target value counts:\\n\", y.value_counts())\n",
        "\n",
        "# 4. Preprocessing: handle missing values and scaling\n",
        "# Missing values appear in Income and Loan_Balance and others in dataset.\n",
        "# Here we impute numeric features with median.\n",
        "num_imputer = SimpleImputer(strategy=\"median\")\n",
        "X_imputed = pd.DataFrame(num_imputer.fit_transform(X), columns=features)\n",
        "\n",
        "# Some rows may still contain extreme or invalid values; it's okay for logistic regression.\n",
        "# Scale features (recommended for regularized logistic regression)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed), columns=features)\n",
        "\n",
        "# ðŸŸ¢ Apply SMOTE to balance the training data\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Before SMOTE:\", y_train.value_counts())\n",
        "print(\"After SMOTE:\", y_res.value_counts())\n",
        "\n",
        "# 5. Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 6. Fit logistic regression model on resampled data\n",
        "model = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
        "model.fit(X_res, y_res)\n",
        "\n",
        "\n",
        "\n",
        "# 7. Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\nEvaluation on test set:\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall: {rec:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "if y_proba is not None:\n",
        "    try:\n",
        "        roc_auc = roc_auc_score(y_test, y_proba)\n",
        "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(\"Could not compute ROC AUC:\", e)\n",
        "\n",
        "# Optional: show feature coefficients (importance)\n",
        "coef_df = pd.DataFrame(\n",
        "    {\"feature\": features, \"coefficient\": model.coef_.ravel()}\n",
        ").sort_values(by=\"coefficient\", key=abs, ascending=False)\n",
        "print(\"\\nFeature coefficients:\")\n",
        "print(coef_df)\n",
        "\n",
        "# Print test set size and positive class prevalence for context\n",
        "print(\"\\nTest set size:\", len(y_test))\n",
        "print(\"Positive class rate in test set:\", y_test.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufkafBa_8oyA",
        "outputId": "b7dd49d1-d4b8-4321-b326-6c5f1b193bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows, cols: (500, 19)\n",
            "  Customer_ID  Age    Income  Credit_Score  Credit_Utilization  \\\n",
            "0    CUST0001   56  165580.0         398.0            0.390502   \n",
            "1    CUST0002   69  100999.0         493.0            0.312444   \n",
            "2    CUST0003   46  188416.0         500.0            0.359930   \n",
            "\n",
            "   Missed_Payments  Delinquent_Account  Loan_Balance  Debt_to_Income_Ratio  \\\n",
            "0                3                   0       16310.0              0.317396   \n",
            "1                6                   1       17401.0              0.196093   \n",
            "2                0                   0       13761.0              0.301655   \n",
            "\n",
            "  Employment_Status  Account_Tenure Credit_Card_Type     Location Month_1  \\\n",
            "0               EMP              18          Student  Los Angeles    Late   \n",
            "1     Self-employed               0         Standard      Phoenix  Missed   \n",
            "2     Self-employed               1         Platinum      Chicago  Missed   \n",
            "\n",
            "  Month_2 Month_3  Month_4  Month_5  Month_6  \n",
            "0    Late  Missed     Late   Missed     Late  \n",
            "1  Missed    Late   Missed  On-time  On-time  \n",
            "2    Late    Late  On-time   Missed     Late  \n",
            "Target value counts:\n",
            " Delinquent_Account\n",
            "0    420\n",
            "1     80\n",
            "Name: count, dtype: int64\n",
            "Before SMOTE: Delinquent_Account\n",
            "0    336\n",
            "1     64\n",
            "Name: count, dtype: int64\n",
            "After SMOTE: Delinquent_Account\n",
            "0    336\n",
            "1    336\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Evaluation on test set:\n",
            "Accuracy: 0.4800\n",
            "Precision: 0.1400\n",
            "Recall: 0.4375\n",
            "F1-score: 0.2121\n",
            "Confusion matrix:\n",
            "[[41 43]\n",
            " [ 9  7]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.49      0.61        84\n",
            "           1       0.14      0.44      0.21        16\n",
            "\n",
            "    accuracy                           0.48       100\n",
            "   macro avg       0.48      0.46      0.41       100\n",
            "weighted avg       0.71      0.48      0.55       100\n",
            "\n",
            "ROC AUC: 0.4382\n",
            "\n",
            "Feature coefficients:\n",
            "                feature  coefficient\n",
            "2                Income     0.254219\n",
            "4        Account_Tenure    -0.176285\n",
            "0    Credit_Utilization     0.110740\n",
            "1       Missed_Payments    -0.071058\n",
            "3  Debt_to_Income_Ratio     0.046316\n",
            "\n",
            "Test set size: 100\n",
            "Positive class rate in test set: 0.16\n"
          ]
        }
      ]
    }
  ]
}